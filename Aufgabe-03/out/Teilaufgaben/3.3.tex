\begin{itemize}
	\item Info(D) = -0.881

	\item $Info_{wind} (D) = \frac{6}{10} \cdot I(4,2) + \frac{4}{10} \cdot I(3,1) \approx 0.94$
	\item $Info_{DaMi} (D) = \frac{7}{10} \cdot I(6,1) + \frac{3}{10} \cdot I(1,2) \approx 0.78$

	\item $Info_wind (D) = 0.056$
	\item --Nach Absprache BREAK --

	\item Die Entropy gibt an wie "vermischt" Werte eines Datensatzes sind.
	 Der Versuch einen Stein hochzuwerfen und zu beobachten ob er wieder herunterkommt ist ein Versuch mit sehr geringer Entropy, wohingegen das erkennen von Gesichtern eine hohe Entropy hat. Jedes Pixel hält einen sehr kleinen Informationsgewinn. 
	So versuchen wir herauszufinden wie viel Information in einem Attribut steckt.
	Am Beispiel des Surfens hat das Attribut 'Enough wind' eine höhere Entropie mit 'Go Surfing' als 'Prepared DaMi', was bedeutet, dass im Entscheidungsprozess für 'Go Surfing' 'Prepared DaMi' eine höhere Rolle spielt.

\end{itemize}
